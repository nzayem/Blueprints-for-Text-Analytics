{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d35aee81-0df2-4273-9660-9ae71fdddfbf",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\">Preparing Textual Data for Statistics and Machine Learning</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5691aaee-ca57-47e3-9df5-160d1309ff0c",
   "metadata": {},
   "source": [
    "We will be using the reddit self posts available in Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df57fe09-7e66-40d8-bce4-a22dc084bfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "posts_file = \"C:\\\\Users\\\\nzaye\\\\Desktop\\\\Machine_learning\\\\data\\\\reddit\\\\rspct.tsv\"\n",
    "posts_df = pd.read_csv(posts_file, sep='\\t')\n",
    "\n",
    "subred_file = \"C:\\\\Users\\\\nzaye\\\\Desktop\\\\Machine_learning\\\\data\\\\reddit\\\\subreddit_info.csv\"\n",
    "subred_df = pd.read_csv(subred_file).set_index(['subreddit'])\n",
    "\n",
    "df = posts_df.join(subred_df, on='subreddit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aeccdea-0786-4d32-b1aa-5e212f77513c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'subreddit', 'title', 'selftext', 'category_1', 'category_2',\n",
       "       'category_3', 'in_data', 'reason_for_exclusion'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b7961ee-7e81-4d70-b087-9c6f3d2d7938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>in_data</th>\n",
       "      <th>reason_for_exclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6d8knd</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>Remember your command line switches...</td>\n",
       "      <td>Hi there,  &lt;lb&gt;The usual. Long time lerker, fi...</td>\n",
       "      <td>writing/stories</td>\n",
       "      <td>tech support</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58mbft</td>\n",
       "      <td>teenmom</td>\n",
       "      <td>So what was Matt \"addicted\" to?</td>\n",
       "      <td>Did he ever say what his addiction was or is h...</td>\n",
       "      <td>tv_show</td>\n",
       "      <td>teen mom</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8f73s7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>No Club Colors</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6ti6re</td>\n",
       "      <td>ringdoorbell</td>\n",
       "      <td>Not door bell, but floodlight mount height.</td>\n",
       "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
       "      <td>hardware/tools</td>\n",
       "      <td>doorbells</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77sxto</td>\n",
       "      <td>intel</td>\n",
       "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
       "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
       "      <td>electronics</td>\n",
       "      <td>cpu</td>\n",
       "      <td>intel</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             subreddit  \\\n",
       "0  6d8knd  talesfromtechsupport   \n",
       "1  58mbft               teenmom   \n",
       "2  8f73s7                Harley   \n",
       "3  6ti6re          ringdoorbell   \n",
       "4  77sxto                 intel   \n",
       "\n",
       "                                               title  \\\n",
       "0             Remember your command line switches...   \n",
       "1                    So what was Matt \"addicted\" to?   \n",
       "2                                     No Club Colors   \n",
       "3        Not door bell, but floodlight mount height.   \n",
       "4  Worried about my 8700k small fft/data stress r...   \n",
       "\n",
       "                                            selftext       category_1  \\\n",
       "0  Hi there,  <lb>The usual. Long time lerker, fi...  writing/stories   \n",
       "1  Did he ever say what his addiction was or is h...          tv_show   \n",
       "2  Funny story. I went to college in Las Vegas. T...            autos   \n",
       "3  I know this is a sub for the 'Ring Doorbell' b...   hardware/tools   \n",
       "4  Prime95 (regardless of version) and OCCT both,...      electronics   \n",
       "\n",
       "        category_2 category_3  in_data reason_for_exclusion  \n",
       "0     tech support        NaN     True                  NaN  \n",
       "1         teen mom        NaN     True                  NaN  \n",
       "2  harley davidson        NaN     True                  NaN  \n",
       "3        doorbells        NaN     True                  NaN  \n",
       "4              cpu      intel     True                  NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743d75c0-e085-4502-b1a5-9b7801057e89",
   "metadata": {},
   "source": [
    "### **Blueprint: Standardizing Attribute Names**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74111da-5112-41e6-a212-9432185712a6",
   "metadata": {},
   "source": [
    "Before we start working with the data, we will change the dataset-specific column names to more generic names. We recommend always naming the main DataFrame df, and naming the column with the text to analyze text. Such naming conventions for common variables and attribute names make it\n",
    "easier to reuse the code of the blueprints in different projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22655d18-125f-47bd-8367-bd866ddb0b71",
   "metadata": {},
   "source": [
    "For column renaming and selection, we define a dictionary column_mapping where each entry defines a mapping from the current column name to a new name. Columns mapped to None and unmentioned columns are dropped. A dictionary is perfect documentation for such a transformation and easy to reuse. This dictionary is then used to select and rename the columns that we want to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22c75cb2-1c8e-4f8f-9cf5-dc81db9474a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'id': 'id',\n",
    "    'subreddit': 'subreddit',\n",
    "    'title': 'title',\n",
    "    'selftext': 'text',\n",
    "    'category_1': 'category',\n",
    "    'category_2': 'subcategory',\n",
    "    'category_3': None, # no data\n",
    "    'in_data': None, # not needed\n",
    "    'reason_for_exclusion': None # not needed\n",
    "}\n",
    "\n",
    "# define remaning columns:\n",
    "columns = [c for c in column_mapping.keys() if column_mapping[c] != None]\n",
    "\n",
    "# select and remove those columns:\n",
    "df = df[columns].rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "546fde84-1402-43be-8fae-ae8df21f00dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'subreddit', 'title', 'text', 'category', 'subcategory'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b43dc467-e6e8-4217-8539-d95ec4316bb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>332921</th>\n",
       "      <td>8j1n1r</td>\n",
       "      <td>Tinder</td>\n",
       "      <td>Does changing gender preference effect your pr...</td>\n",
       "      <td>I've always dated women but I'm opening myself...</td>\n",
       "      <td>company/website</td>\n",
       "      <td>online dating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id subreddit                                              title  \\\n",
       "332921  8j1n1r    Tinder  Does changing gender preference effect your pr...   \n",
       "\n",
       "                                                     text         category  \\\n",
       "332921  I've always dated women but I'm opening myself...  company/website   \n",
       "\n",
       "          subcategory  \n",
       "332921  online dating  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faf61ede-981d-482a-a3a0-14c3c63cb32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>495150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>75zanc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <td>cigars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>Trade with /u/gdalam proves I need to step up ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>I'm totally blown away! Just got a package fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subcategory</th>\n",
       "      <td>tobacco</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        495150\n",
       "id                                                      75zanc\n",
       "subreddit                                               cigars\n",
       "title        Trade with /u/gdalam proves I need to step up ...\n",
       "text         I'm totally blown away! Just got a package fro...\n",
       "category                                                 drugs\n",
       "subcategory                                            tobacco"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(1).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6832323e-2676-40d2-99a2-85062c6024e8",
   "metadata": {},
   "source": [
    "### Saving the dataframe in a SQLITE database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68ecbd37-2764-48f3-aa6d-25e9e9600d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "db_name = 'reddit-selfposts.db'\n",
    "con = sqlite3.connect(db_name)\n",
    "df.to_sql('posts', con, index=False, if_exists=\"replace\")\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb840ec9-0d38-456e-8fcc-ecea67aa355c",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(db_name)\n",
    "df = pd.read_sql(\"select * from posts\", con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e7e92e-fabc-4b51-9bff-3a0188afe0ca",
   "metadata": {},
   "source": [
    "## Cleaning Text Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd15b2-2526-46ff-b384-1efb46e8f243",
   "metadata": {},
   "source": [
    "### **Blueprint: Identify Noise with Regular Expressions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7efcf8d-1cb4-4387-b8fb-982cade102b0",
   "metadata": {},
   "source": [
    "The idea is to set up some metrics to describe the quality of text with regards to the noise (e.g.: html tags...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eda585a-4d33-48ec-9f0b-88a7a5200b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "RE_SUSPICIOUS = re.compile(r'[&#<>{}\\[\\]\\\\]')\n",
    "\n",
    "\n",
    "def impurity(text, min_len=10):\n",
    "    \n",
    "    \"\"\"returns the share of suspicious characters in a text\"\"\"\n",
    "    if text == None or len(text) < min_len:\n",
    "        return 0\n",
    "    else:\n",
    "        return len(RE_SUSPICIOUS.findall(text))/len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e08fdf77-8c5e-4097-b09a-f226676a7df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column to data frame\n",
    "df['impurity'] = df['text'].apply(impurity, min_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a8df0b4e-1c94-473a-a0d9-1ea73d249ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>impurity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>513243</th>\n",
       "      <td>Here's all of their singles, so none of these ...</td>\n",
       "      <td>0.302914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966949</th>\n",
       "      <td>I think it might just be gibberish, but I want...</td>\n",
       "      <td>0.292324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421581</th>\n",
       "      <td>I find if you search using terms related to th...</td>\n",
       "      <td>0.289977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  impurity\n",
       "513243  Here's all of their singles, so none of these ...  0.302914\n",
       "966949  I think it might just be gibberish, but I want...  0.292324\n",
       "421581  I find if you search using terms related to th...  0.289977"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top 3 records\n",
    "df[['text', 'impurity']].sort_values(by='impurity', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644c3f3f-5a68-4529-9a30-e290f730daec",
   "metadata": {},
   "source": [
    "**Function count_words from Chapter One**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fd446cb-b30c-4802-bc6d-b19cd7996eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def count_words(df, column='tokens', preprocess=None, min_freq=2):\n",
    "    \n",
    "    # process tokens and update counter\n",
    "    def update(doc):\n",
    "        tokens = doc if preprocess is None else preprocess(doc)\n",
    "        counter.update(tokens)\n",
    "        \n",
    "    # create counter and run through all data\n",
    "    counter = Counter()\n",
    "    df[column].map(update)\n",
    "    \n",
    "    # transform counter into a DataFrame\n",
    "    freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq'])\n",
    "    freq_df = freq_df.query('freq >= @min_freq')\n",
    "    freq_df.index.name = 'token'\n",
    "    return freq_df.sort_values('freq', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53248e23-61f1-42ea-b7f5-dd4d0df3332b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;lb&gt;</th>\n",
       "      <td>6753605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;tab&gt;</th>\n",
       "      <td>95917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          freq\n",
       "token         \n",
       "<lb>   6753605\n",
       "<tab>    95917"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_words(df, column='text', preprocess=lambda t: re.findall(r'<[\\w/]*>', t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a0f8cc-5de3-4076-b71a-d49bcdd12e95",
   "metadata": {},
   "source": [
    "Now we know that although these two tags are common, they are the only ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b6407f-1e63-4498-8b3a-5f9925e799e2",
   "metadata": {},
   "source": [
    "### **Blueprint: Removing Noise with Regular Expressions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35ade68c-ea71-49be-a427-e197115e88c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "\n",
    "def clean(text):\n",
    "    \n",
    "    # convert html escapes like &amp; to characters.\n",
    "    text = html.unescape(text)\n",
    "    \n",
    "    # tags like <tab>\n",
    "    text = re.sub(r'<[^<>]*>', ' ', text)\n",
    "    \n",
    "    # markdown URLs like [Some text](https://....)\n",
    "    text = re.sub(r'\\[([^\\[\\]]*)\\]\\([^\\(\\)]*\\)', r'\\1', text)\n",
    "    \n",
    "    # text or code in brackets like [0]\n",
    "    text = re.sub(r'\\[[^\\[\\]]*\\]', ' ', text)\n",
    "    \n",
    "    # standalone sequences of specials, matches &# but not #cool\n",
    "    text = re.sub(r'(?:^|\\s)[&#<>{}\\[\\]+|\\\\:-]{1,}(?:\\s|$)', ' ', text)\n",
    "    \n",
    "    # standalone sequences of hyphens like --- or ==\n",
    "    text = re.sub(r'(?:^|\\s)[\\-=\\+]{2,}(?:\\s|$)', ' ', text)\n",
    "    \n",
    "    # sequences of white spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f1995b4-a7e4-4f0e-b3c4-49d657587420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['text'].map(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8b38b54-0aca-4ee0-aa23-cd5349a674d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>impurity</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>660720</th>\n",
       "      <td>89ac2u</td>\n",
       "      <td>Meditation</td>\n",
       "      <td>Trouble visualizing white light</td>\n",
       "      <td>Hi, I've recently been trying to do a lot of m...</td>\n",
       "      <td>health</td>\n",
       "      <td>mindfulness/meditation</td>\n",
       "      <td>0.01766</td>\n",
       "      <td>Hi, I've recently been trying to do a lot of m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id   subreddit                            title  \\\n",
       "660720  89ac2u  Meditation  Trouble visualizing white light   \n",
       "\n",
       "                                                     text category  \\\n",
       "660720  Hi, I've recently been trying to do a lot of m...   health   \n",
       "\n",
       "                   subcategory  impurity  \\\n",
       "660720  mindfulness/meditation   0.01766   \n",
       "\n",
       "                                               clean_text  \n",
       "660720  Hi, I've recently been trying to do a lot of m...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bccd7b31-74b2-4754-b832-29a36b69c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the impurity of the clean text\n",
    "df['impurity'] = df['clean_text'].apply(impurity, min_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d67b34f7-36d8-4c84-b867-137a356da45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>impurity</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6d8knd</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>Remember your command line switches...</td>\n",
       "      <td>Hi there,  &lt;lb&gt;The usual. Long time lerker, fi...</td>\n",
       "      <td>writing/stories</td>\n",
       "      <td>tech support</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hi there, The usual. Long time lerker, first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58mbft</td>\n",
       "      <td>teenmom</td>\n",
       "      <td>So what was Matt \"addicted\" to?</td>\n",
       "      <td>Did he ever say what his addiction was or is h...</td>\n",
       "      <td>tv_show</td>\n",
       "      <td>teen mom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Did he ever say what his addiction was or is h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8f73s7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>No Club Colors</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6ti6re</td>\n",
       "      <td>ringdoorbell</td>\n",
       "      <td>Not door bell, but floodlight mount height.</td>\n",
       "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
       "      <td>hardware/tools</td>\n",
       "      <td>doorbells</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77sxto</td>\n",
       "      <td>intel</td>\n",
       "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
       "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
       "      <td>electronics</td>\n",
       "      <td>cpu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             subreddit  \\\n",
       "0  6d8knd  talesfromtechsupport   \n",
       "1  58mbft               teenmom   \n",
       "2  8f73s7                Harley   \n",
       "3  6ti6re          ringdoorbell   \n",
       "4  77sxto                 intel   \n",
       "\n",
       "                                               title  \\\n",
       "0             Remember your command line switches...   \n",
       "1                    So what was Matt \"addicted\" to?   \n",
       "2                                     No Club Colors   \n",
       "3        Not door bell, but floodlight mount height.   \n",
       "4  Worried about my 8700k small fft/data stress r...   \n",
       "\n",
       "                                                text         category  \\\n",
       "0  Hi there,  <lb>The usual. Long time lerker, fi...  writing/stories   \n",
       "1  Did he ever say what his addiction was or is h...          tv_show   \n",
       "2  Funny story. I went to college in Las Vegas. T...            autos   \n",
       "3  I know this is a sub for the 'Ring Doorbell' b...   hardware/tools   \n",
       "4  Prime95 (regardless of version) and OCCT both,...      electronics   \n",
       "\n",
       "       subcategory  impurity  \\\n",
       "0     tech support       0.0   \n",
       "1         teen mom       0.0   \n",
       "2  harley davidson       0.0   \n",
       "3        doorbells       0.0   \n",
       "4              cpu       0.0   \n",
       "\n",
       "                                          clean_text  \n",
       "0  Hi there, The usual. Long time lerker, first t...  \n",
       "1  Did he ever say what his addiction was or is h...  \n",
       "2  Funny story. I went to college in Las Vegas. T...  \n",
       "3  I know this is a sub for the 'Ring Doorbell' b...  \n",
       "4  Prime95 (regardless of version) and OCCT both,...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cdb44f4-0582-422c-ad63-1d314bddd221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>impurity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>901234</th>\n",
       "      <td>I've ran our site through multiple scanners an...</td>\n",
       "      <td>0.223554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818363</th>\n",
       "      <td>Please use this form to post custom cipher sol...</td>\n",
       "      <td>0.202572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>825981</th>\n",
       "      <td>I have used the preclear plugin before without...</td>\n",
       "      <td>0.179025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               clean_text  impurity\n",
       "901234  I've ran our site through multiple scanners an...  0.223554\n",
       "818363  Please use this form to post custom cipher sol...  0.202572\n",
       "825981  I have used the preclear plugin before without...  0.179025"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['clean_text', 'impurity']].sort_values(by='impurity', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65fafc-9807-425f-b724-84a81b07dc0f",
   "metadata": {},
   "source": [
    "## **Blueprint: Character Normalization with textacy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a7151d-86eb-49c8-b734-8829215d18f7",
   "metadata": {},
   "source": [
    "Accented characters can be a problem because people do not consistently use them. For example, the tokens Saint-Raphaël and Saint-Raphael will not be recognized as identical. In addition, texts often contain words separated by a hyphen due to the automatic line breaks. Fancy Unicode hyphens and apostrophes like the ones used in the text can be a problem for tokenization. For all of these issues it makes sense to normalize the text and replace accents and fancy characters with ASCII equivalents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878177a9-4e10-4a3e-b3e6-93cfd40487ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install textacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3454b267-0fb7-41c2-9b93-ea345e88eb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy.preprocessing as tprep\n",
    "\n",
    "\n",
    "def normalize(text):\n",
    "    text = tprep.normalize.hyphenated_words(text)\n",
    "    text = tprep.normalize.quotation_marks(text)\n",
    "    text = tprep.normalize.unicode(text)\n",
    "    text = tprep.remove.accents(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39e3a672-c9b5-4420-b80c-8240dd2cd185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cafe \"Saint-Raphael\" is located on Cote d'Azur.\n"
     ]
    }
   ],
   "source": [
    "sometext = \"The café “Saint-Raphaël” is loca-\\nted on Côte dʼAzur.\"\n",
    "\n",
    "print(normalize(sometext))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d269dd58-3073-49be-977e-c9bc6bc68f8b",
   "metadata": {},
   "source": [
    ">As Unicode normalization has many facets, you can check out other libraries. unidecode, for example, does an excellent job here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a997a07-cf42-488f-8004-c6b056114324",
   "metadata": {},
   "source": [
    "## **Blueprint: Pattern-Based Data Masking with textacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1341f505-85d9-4b7c-8e05-ea7d6f4c91d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>https://keybase.io/crypto</th>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.pokemon.com/TCGO</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.google.com</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www.reddit.com</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://battlescribe.net</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           freq\n",
       "token                          \n",
       "https://keybase.io/crypto   275\n",
       "www.pokemon.com/TCGO         49\n",
       "www.google.com               38\n",
       "www.reddit.com               32\n",
       "https://battlescribe.net     29"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textacy.preprocessing.resources import RE_URL\n",
    "\n",
    "count_words(df, column='clean_text', preprocess=RE_URL.findall).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea6d4ee-5c1f-46f9-98a6-9d1ca9a94c19",
   "metadata": {},
   "source": [
    "For the analysis we want to perform with this dataset (in Chapter 10), we are not interested in those URLs. They rather represent a disturbing artifact. Thus, we will substitute all URLs in our text with replace_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d5ae5714-9c8a-4c17-a6e2-35cf638ef01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check out _URL_\n"
     ]
    }
   ],
   "source": [
    "from textacy.preprocessing.replace import urls\n",
    "\n",
    "sometext = \"Check out https://spacy.io/usage/spacy-101\"\n",
    "# using default substitution _URL_\n",
    "print(urls(sometext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "35ee94fd-0567-4321-9f65-a9532d9eb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['clean_text'].map(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b530b26b-a9bb-4325-803b-2541f0f0b0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>impurity</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6d8knd</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>Remember your command line switches...</td>\n",
       "      <td>Hi there,  &lt;lb&gt;The usual. Long time lerker, fi...</td>\n",
       "      <td>writing/stories</td>\n",
       "      <td>tech support</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hi there, The usual. Long time lerker, first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58mbft</td>\n",
       "      <td>teenmom</td>\n",
       "      <td>So what was Matt \"addicted\" to?</td>\n",
       "      <td>Did he ever say what his addiction was or is h...</td>\n",
       "      <td>tv_show</td>\n",
       "      <td>teen mom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Did he ever say what his addiction was or is h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8f73s7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>No Club Colors</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6ti6re</td>\n",
       "      <td>ringdoorbell</td>\n",
       "      <td>Not door bell, but floodlight mount height.</td>\n",
       "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
       "      <td>hardware/tools</td>\n",
       "      <td>doorbells</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77sxto</td>\n",
       "      <td>intel</td>\n",
       "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
       "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
       "      <td>electronics</td>\n",
       "      <td>cpu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             subreddit  \\\n",
       "0  6d8knd  talesfromtechsupport   \n",
       "1  58mbft               teenmom   \n",
       "2  8f73s7                Harley   \n",
       "3  6ti6re          ringdoorbell   \n",
       "4  77sxto                 intel   \n",
       "\n",
       "                                               title  \\\n",
       "0             Remember your command line switches...   \n",
       "1                    So what was Matt \"addicted\" to?   \n",
       "2                                     No Club Colors   \n",
       "3        Not door bell, but floodlight mount height.   \n",
       "4  Worried about my 8700k small fft/data stress r...   \n",
       "\n",
       "                                                text         category  \\\n",
       "0  Hi there,  <lb>The usual. Long time lerker, fi...  writing/stories   \n",
       "1  Did he ever say what his addiction was or is h...          tv_show   \n",
       "2  Funny story. I went to college in Las Vegas. T...            autos   \n",
       "3  I know this is a sub for the 'Ring Doorbell' b...   hardware/tools   \n",
       "4  Prime95 (regardless of version) and OCCT both,...      electronics   \n",
       "\n",
       "       subcategory  impurity  \\\n",
       "0     tech support       0.0   \n",
       "1         teen mom       0.0   \n",
       "2  harley davidson       0.0   \n",
       "3        doorbells       0.0   \n",
       "4              cpu       0.0   \n",
       "\n",
       "                                          clean_text  \n",
       "0  Hi there, The usual. Long time lerker, first t...  \n",
       "1  Did he ever say what his addiction was or is h...  \n",
       "2  Funny story. I went to college in Las Vegas. T...  \n",
       "3  I know this is a sub for the 'Ring Doorbell' b...  \n",
       "4  Prime95 (regardless of version) and OCCT both,...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d62875d8-3e34-401b-a54b-a53646e7eb1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = df['clean_text'].map(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ded29a-70c1-4622-8535-fc8b09149363",
   "metadata": {},
   "source": [
    "We finally rename the text columns so that clean_text becomes text, drop the impurity column, and store the new version of the DataFrame in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "10e975bd-53cb-4b9f-bb5c-086da053ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'text': 'raw_text', 'clean_text': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a38f128-286d-486b-9974-b03fb664657f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>impurity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6d8knd</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>Remember your command line switches...</td>\n",
       "      <td>Hi there,  &lt;lb&gt;The usual. Long time lerker, fi...</td>\n",
       "      <td>writing/stories</td>\n",
       "      <td>tech support</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hi there, The usual. Long time lerker, first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58mbft</td>\n",
       "      <td>teenmom</td>\n",
       "      <td>So what was Matt \"addicted\" to?</td>\n",
       "      <td>Did he ever say what his addiction was or is h...</td>\n",
       "      <td>tv_show</td>\n",
       "      <td>teen mom</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Did he ever say what his addiction was or is h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8f73s7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>No Club Colors</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6ti6re</td>\n",
       "      <td>ringdoorbell</td>\n",
       "      <td>Not door bell, but floodlight mount height.</td>\n",
       "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
       "      <td>hardware/tools</td>\n",
       "      <td>doorbells</td>\n",
       "      <td>0.0</td>\n",
       "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77sxto</td>\n",
       "      <td>intel</td>\n",
       "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
       "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
       "      <td>electronics</td>\n",
       "      <td>cpu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             subreddit  \\\n",
       "0  6d8knd  talesfromtechsupport   \n",
       "1  58mbft               teenmom   \n",
       "2  8f73s7                Harley   \n",
       "3  6ti6re          ringdoorbell   \n",
       "4  77sxto                 intel   \n",
       "\n",
       "                                               title  \\\n",
       "0             Remember your command line switches...   \n",
       "1                    So what was Matt \"addicted\" to?   \n",
       "2                                     No Club Colors   \n",
       "3        Not door bell, but floodlight mount height.   \n",
       "4  Worried about my 8700k small fft/data stress r...   \n",
       "\n",
       "                                            raw_text         category  \\\n",
       "0  Hi there,  <lb>The usual. Long time lerker, fi...  writing/stories   \n",
       "1  Did he ever say what his addiction was or is h...          tv_show   \n",
       "2  Funny story. I went to college in Las Vegas. T...            autos   \n",
       "3  I know this is a sub for the 'Ring Doorbell' b...   hardware/tools   \n",
       "4  Prime95 (regardless of version) and OCCT both,...      electronics   \n",
       "\n",
       "       subcategory  impurity  \\\n",
       "0     tech support       0.0   \n",
       "1         teen mom       0.0   \n",
       "2  harley davidson       0.0   \n",
       "3        doorbells       0.0   \n",
       "4              cpu       0.0   \n",
       "\n",
       "                                                text  \n",
       "0  Hi there, The usual. Long time lerker, first t...  \n",
       "1  Did he ever say what his addiction was or is h...  \n",
       "2  Funny story. I went to college in Las Vegas. T...  \n",
       "3  I know this is a sub for the 'Ring Doorbell' b...  \n",
       "4  Prime95 (regardless of version) and OCCT both,...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8566e6ad-3a5a-4faf-b154-732ccfcf26a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['impurity'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "73b949a7-9d8c-4342-8d01-430a1b55056c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6d8knd</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>Remember your command line switches...</td>\n",
       "      <td>Hi there,  &lt;lb&gt;The usual. Long time lerker, fi...</td>\n",
       "      <td>writing/stories</td>\n",
       "      <td>tech support</td>\n",
       "      <td>Hi there, The usual. Long time lerker, first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58mbft</td>\n",
       "      <td>teenmom</td>\n",
       "      <td>So what was Matt \"addicted\" to?</td>\n",
       "      <td>Did he ever say what his addiction was or is h...</td>\n",
       "      <td>tv_show</td>\n",
       "      <td>teen mom</td>\n",
       "      <td>Did he ever say what his addiction was or is h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8f73s7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>No Club Colors</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6ti6re</td>\n",
       "      <td>ringdoorbell</td>\n",
       "      <td>Not door bell, but floodlight mount height.</td>\n",
       "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
       "      <td>hardware/tools</td>\n",
       "      <td>doorbells</td>\n",
       "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77sxto</td>\n",
       "      <td>intel</td>\n",
       "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
       "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
       "      <td>electronics</td>\n",
       "      <td>cpu</td>\n",
       "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             subreddit  \\\n",
       "0  6d8knd  talesfromtechsupport   \n",
       "1  58mbft               teenmom   \n",
       "2  8f73s7                Harley   \n",
       "3  6ti6re          ringdoorbell   \n",
       "4  77sxto                 intel   \n",
       "\n",
       "                                               title  \\\n",
       "0             Remember your command line switches...   \n",
       "1                    So what was Matt \"addicted\" to?   \n",
       "2                                     No Club Colors   \n",
       "3        Not door bell, but floodlight mount height.   \n",
       "4  Worried about my 8700k small fft/data stress r...   \n",
       "\n",
       "                                            raw_text         category  \\\n",
       "0  Hi there,  <lb>The usual. Long time lerker, fi...  writing/stories   \n",
       "1  Did he ever say what his addiction was or is h...          tv_show   \n",
       "2  Funny story. I went to college in Las Vegas. T...            autos   \n",
       "3  I know this is a sub for the 'Ring Doorbell' b...   hardware/tools   \n",
       "4  Prime95 (regardless of version) and OCCT both,...      electronics   \n",
       "\n",
       "       subcategory                                               text  \n",
       "0     tech support  Hi there, The usual. Long time lerker, first t...  \n",
       "1         teen mom  Did he ever say what his addiction was or is h...  \n",
       "2  harley davidson  Funny story. I went to college in Las Vegas. T...  \n",
       "3        doorbells  I know this is a sub for the 'Ring Doorbell' b...  \n",
       "4              cpu  Prime95 (regardless of version) and OCCT both,...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f444f95-ead2-4f9c-9d6d-fff655454338",
   "metadata": {},
   "source": [
    "Saving in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a2c1d69b-c133-444b-af0d-814c35b78870",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(db_name)\n",
    "df.to_sql(\"posts_cleaned\", con, index=False, if_exists=\"replace\")\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36737089-c934-4b3e-a1dc-942d83da5734",
   "metadata": {},
   "source": [
    "## **Linguistic Processing with spaCy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064df92-b65f-4460-a97b-4b36eafd8e9f",
   "metadata": {},
   "source": [
    "**Instantiating a Pipeline**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc57f50-9063-4da4-939b-afcb92cca936",
   "metadata": {},
   "source": [
    "As a first step we need to instantiate an object of spaCy’s Language class by calling spacy.load() along with the name of the model file to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b529bab9-1028-493d-bbf2-1287da34061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "660998fb-83a7-42e2-b3ce-7af4b497660a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x1ad9433fe80>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x1adac4a3ca0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x1ae526cbd80>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x1aea673d500>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1aea67784c0>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x1ae526cbf40>)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1210175c-3651-433e-8003-4f917bf590ac",
   "metadata": {},
   "source": [
    "**Utility function: display_nlp to generate a table containing the tokens and their attributes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "63870b82-85ae-46a9-814d-ca7bdb453174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_nlp(doc, include_punct=False):\n",
    "    \n",
    "    \"\"\"Generate data frame for visualization of spaCy tokens.\"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for i, t in enumerate(doc):\n",
    "        \n",
    "        if not t.is_punct or include_punct:\n",
    "            row = {'token': i, 'text': t.text, 'lemma_': t.lemma_, 'is_stop': t.is_stop, \n",
    "                   'is_alpha': t.is_alpha, 'pos_': t.pos_, 'dep_': t.dep_,\n",
    "                   'ent_type_': t.ent_type_, 'ent_iob_': t.ent_iob_}\n",
    "            rows.append(row)\n",
    "            \n",
    "    df = pd.DataFrame(rows).set_index('token')\n",
    "    df.index.name = None\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f95ba80e-79fb-4892-9315-40f9ca526fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"My best friend Ryan Peters likes fancy adventure games.\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fa0abc6f-9948-4607-aa93-0447469e2222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemma_</th>\n",
       "      <th>is_stop</th>\n",
       "      <th>is_alpha</th>\n",
       "      <th>pos_</th>\n",
       "      <th>dep_</th>\n",
       "      <th>ent_type_</th>\n",
       "      <th>ent_iob_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My</td>\n",
       "      <td>my</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>PRON</td>\n",
       "      <td>poss</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best</td>\n",
       "      <td>good</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>friend</td>\n",
       "      <td>friend</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>nsubj</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ryan</td>\n",
       "      <td>Ryan</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>compound</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Peters</td>\n",
       "      <td>Peters</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>appos</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>likes</td>\n",
       "      <td>like</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>VERB</td>\n",
       "      <td>ROOT</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fancy</td>\n",
       "      <td>fancy</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>amod</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adventure</td>\n",
       "      <td>adventure</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>compound</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>games</td>\n",
       "      <td>game</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>dobj</td>\n",
       "      <td></td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text     lemma_  is_stop  is_alpha   pos_      dep_ ent_type_ ent_iob_\n",
       "0         My         my     True      True   PRON      poss                  O\n",
       "1       best       good    False      True    ADJ      amod                  O\n",
       "2     friend     friend    False      True   NOUN     nsubj                  O\n",
       "3       Ryan       Ryan    False      True  PROPN  compound    PERSON        B\n",
       "4     Peters     Peters    False      True  PROPN     appos    PERSON        I\n",
       "5      likes       like    False      True   VERB      ROOT                  O\n",
       "6      fancy      fancy    False      True    ADJ      amod                  O\n",
       "7  adventure  adventure    False      True   NOUN  compound                  O\n",
       "8      games       game    False      True   NOUN      dobj                  O"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_nlp(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f91e57c-bbe1-4e67-a0c1-2b8f346f6042",
   "metadata": {
    "tags": []
   },
   "source": [
    "## **Blueprint: Customizing Tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b9ed8-dd65-46b3-a191-e3a4f6ceab0a",
   "metadata": {},
   "source": [
    "Tokenization is the first step in the pipeline. spaCy’s tokenizer does a good job in most cases, but it splits on hash signs, hyphens, and underscores, which is sometimes not what you want. Therefore, it may be necessary to adjust its behavior. Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7bcd47c9-5b56-45f0-ac6f-769b3dc563d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Pete|:|choose|low|-|carb|#|food|#|eat|-|smart|.|_|url|_|;-)|😋|👍|"
     ]
    }
   ],
   "source": [
    "text = \"@Pete: choose low-carb #food #eat-smart. _url_ ;-) 😋👍\"\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522ac878-dfe7-4427-9f40-73bdceb45d43",
   "metadata": {},
   "source": [
    "The best approach for this is to create your own variant of the tokenizer with individual rules for infix, prefix, and suffix splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "29007c12-61d3-4ab2-80ce-643772181b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex\n",
    "\n",
    "def custom_tokenizer(nlp):\n",
    "    \n",
    "    # use default patterns except the ones matched by re.search\n",
    "    prefixes = [pattern for pattern in nlp.Defaults.prefixes if pattern not in ['-', '_', '#']]\n",
    "    suffixes = [pattern for pattern in nlp.Defaults.suffixes if pattern not in ['_']]\n",
    "    infixes  = [pattern for pattern in nlp.Defaults.infixes if not re.search(pattern, 'xx-xx')]\n",
    "\n",
    "    return Tokenizer(vocab          = nlp.vocab, \n",
    "                     rules          = nlp.Defaults.tokenizer_exceptions,\n",
    "                     prefix_search  = compile_prefix_regex(prefixes).search,\n",
    "                     suffix_search  = compile_suffix_regex(suffixes).search,\n",
    "                     infix_finditer = compile_infix_regex(infixes).finditer,\n",
    "                     token_match    = nlp.Defaults.token_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "efaf6eb3-590b-44a9-b737-1a6b82d86bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@Pete|:|choose|low-carb|#food|#eat-smart|.|_url_|;-)|😋|👍|"
     ]
    }
   ],
   "source": [
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "\n",
    "doc = nlp(text)\n",
    "for token in doc:\n",
    "    print(token, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770d1237-b3f6-4b6f-9f17-ec223c9f31ed",
   "metadata": {},
   "source": [
    "## **Blueprint: Working with Stop Words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4408cd2f-da4b-4411-ba72-38832b833f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "text = \"Dear Ryan, we need to sit down and talk. Regards, Pete\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b3517d5e-38ac-4eb5-a623-77c8512873f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Dear, Ryan, need, sit, talk, Regards, Pete]\n"
     ]
    }
   ],
   "source": [
    "non_stop = [t for t in doc if not t.is_stop and not t.is_punct]\n",
    "print(non_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d337a9f0-a537-4bdb-9c6b-810b16f87aea",
   "metadata": {},
   "source": [
    "The list of English stop words with more than 300 entries can be accessed by importing spacy.lang.en.STOP_WORDS. When an nlp object is created, this list is loaded and stored under nlp.Defaults.stop_words. We can modify spaCy’s default behavior by setting the is_stop property of the respective words in spaCy’s vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9844cbe1-b4d5-4ec1-b53f-e41d08796238",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.vocab['down'].is_stop = False\n",
    "nlp.vocab['Dear'].is_stop = True\n",
    "nlp.vocab['Regards'].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "996e1031-0230-45ba-97f6-05b6709c21c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Ryan, need, sit, down, talk, Pete]\n"
     ]
    }
   ],
   "source": [
    "non_stop = [t for t in doc if not t.is_stop and not t.is_punct]\n",
    "print(non_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c22223-44b7-48c4-9a13-bd301e4dd6da",
   "metadata": {},
   "source": [
    "## **Blueprint: Extracting Lemmas Based on Part of Speech**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e8cd1c07-7833-4676-bc7e-9a70ca4bc0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my | good | friend | Ryan | Peters | like | fancy | adventure | game | .\n"
     ]
    }
   ],
   "source": [
    "text = \"My best friend Ryan Peters likes fancy adventure games.\"\n",
    "doc = nlp(text)\n",
    "print(*[t.lemma_ for t in doc], sep=' | ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97502cd4-e038-4344-acf4-2e84b46c7dee",
   "metadata": {},
   "source": [
    "The correct assignment of the lemma requires a lookup dictionary and knowledge about the part of speech of a word. For example, the lemma of the noun meeting is meeting, while the lemma of the verb is meet. In English, spaCy is able to make this distinction. In most other languages, however, lemmatization is purely dictionary-based, ignoring the part-of-speech dependency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401a3d64-16e5-4dda-a790-440535fe4255",
   "metadata": {},
   "source": [
    "Part-of-speech tags are an excellent alternative to stop words as word filters. In linguistics, pronouns, prepositions, conjunctions, and determiners are called function words because their main function is to create grammatical relationships within a sentence. Nouns, verbs, adjectives, and adverbs are content words, and the meaning of a sentence depends mainly on them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849e364f-48af-4a2f-9e48-64a6efc5b4b3",
   "metadata": {},
   "source": [
    "Often, we are interested only in content words. Thus, instead of using a stop word list, we can use part-of-speech tags to select the word types we are interested in and discard the rest. For example, a list containing only the nouns and proper nouns in a doc can be generated like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "934cc909-4faf-40d4-a12e-0753332ea7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[friend, Ryan, Peters, adventure, games]\n"
     ]
    }
   ],
   "source": [
    "text = \"My best friend Ryan Peters likes fancy adventure games.\"\n",
    "doc = nlp(text)\n",
    "nouns = [t for t in doc if t.pos_ in ['NOUN', 'PROPN']]\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9ca640-38ec-4abb-ad4c-769b57e9e7a1",
   "metadata": {},
   "source": [
    "The following example shows how to extract tokens for adjectives and nouns from the sample sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c28b43f9-f077-4074-b778-d0ac8d9e56dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best | friend | fancy | adventure | games\n"
     ]
    }
   ],
   "source": [
    "import textacy\n",
    "\n",
    "tokens = textacy.extract.words(doc,\n",
    "            filter_stops = True, # default True, no stopwords\n",
    "            filter_punct = True, # default True, no punctuation\n",
    "            filter_nums = True, # default False, no numbers\n",
    "            include_pos = ['ADJ', 'NOUN'], # default None = include all\n",
    "            exclude_pos = None, # default None = exclude none\n",
    "            min_freq = 1) # minimum frequency of words\n",
    "\n",
    "print(*[t for t in tokens], sep=' | ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0535f7c7-4418-40f3-bbde-ab483bc72106",
   "metadata": {},
   "source": [
    "**Blueprint function to extract a filtered list of word lemmas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3231733c-16b9-4e90-bfcc-b139001f53a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lemmas(doc, **kwargs):\n",
    "    return [t.lemma_ for t in textacy.extract.words(doc, **kwargs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "abd22684-4973-4605-bc7d-69153989438a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good|friend|fancy|adventure|game\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "lemmas = extract_lemmas(doc, include_pos=['ADJ', 'NOUN'])\n",
    "print(*lemmas, sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501942b6-d136-49ce-a672-388133c8b6e2",
   "metadata": {},
   "source": [
    "## **Blueprint: Extracting Noun Phrases**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fec1e31-e2ed-4ae4-a0bf-e3060b28faa0",
   "metadata": {},
   "source": [
    "Many bigrams are not very useful for analysis, for example, likes_fancy or my_best. It would be even worse for trigrams. But how can we detect word sequences that have real meaning? One way is to apply pattern-matching on the part-of-speech tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cf720aa8-390f-4c2c-b27f-717e4b80d750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good friend|fancy adventure|fancy adventure game\n"
     ]
    }
   ],
   "source": [
    "text = \"My best friend Ryan Peters likes fancy adventure games.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "patterns = [\"POS:ADJ POS:NOUN:+\"]\n",
    "\n",
    "spans = textacy.extract.matches.token_matches(doc, patterns=patterns)\n",
    "\n",
    "print(*[s.lemma_ for s in spans], sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397b8ef5-f61a-4acf-87ac-08ac7a15e7f6",
   "metadata": {},
   "source": [
    "**We define our blueprint function for noun phrase extraction based on part-of-speech patterns.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bbfef471-9221-45e0-b063-3ad8877fe8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_noun_phrases(doc, preceding_pos=['NOUN'], sep='_'):\n",
    "    patterns = []\n",
    "    for pos in preceding_pos:\n",
    "        patterns.append(f\"POS:{pos} POS:NOUN:+\")\n",
    "    \n",
    "    spans = textacy.extract.matches.token_matches(doc, patterns=patterns)\n",
    "    \n",
    "    return [sep.join([t.lemma_ for t in s]) for s in spans]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8975d659-5c96-447f-82e4-c7a224015ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good_friend|fancy_adventure|fancy_adventure_game|adventure_game\n"
     ]
    }
   ],
   "source": [
    "print(*extract_noun_phrases(doc, ['ADJ', 'NOUN']), sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402dfa33-29fb-4033-a03c-9400d968d0b0",
   "metadata": {},
   "source": [
    "## **Blueprint: Extracting Named Entities**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9de6236-976a-475d-ae31-701b6fa0f9ca",
   "metadata": {},
   "source": [
    "Named-entity recognition refers to the process of detecting entities such as people, locations, or organizations in text. Each entity can consist of one or more tokens, like San Francisco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "1bae494c-0506-4b94-9de8-5b914a67d36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "James O'Neill: PERSON\n",
      "World Cargo Inc: ORG\n",
      "San Francisco: GPE\n"
     ]
    }
   ],
   "source": [
    "text = \"James O'Neill, chairman of World Cargo Inc, lives in San Francisco.\"\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text}: {ent.label_}\", end=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "62f6e5cd-62c0-4bd8-974f-4ccc814b8b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    James O'Neill\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       ", chairman of \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    World Cargo Inc\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", lives in \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    San Francisco\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69867966-996f-4937-90c6-43b8eccde47e",
   "metadata": {},
   "source": [
    "For the extraction of named entities of certain types, we again make use of one of textacy’s convenient functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "f02f1b14-85de-4753-9ebc-62a1a765a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(doc, include_types=None, sep='_'):\n",
    "    \n",
    "    ents = textacy.extract.entities(doc, include_types=include_types, exclude_types=None, \n",
    "                                    drop_determiners=True, min_freq=1)\n",
    "    \n",
    "    return [sep.join([t.lemma_ for t in e]) + '/' + e.label_ for e in ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c374c4ae-15b6-4d3f-a6e8-3bfcd677dba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"James_O'Neill/PERSON\", 'San_Francisco/GPE']\n"
     ]
    }
   ],
   "source": [
    "print(extract_entities(doc, ['PERSON', 'GPE']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f191d499-b3c2-4ed1-a29c-1f04b24eb27a",
   "metadata": {},
   "source": [
    "# **Feature Extraction on a Large Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17460d2-4c26-4581-aeb4-ae57352f4afd",
   "metadata": {},
   "source": [
    "## **Blueprint: Creating One Function to Get It All**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cc536d-7346-4eda-9bb9-c41a1c6e55e2",
   "metadata": {},
   "source": [
    "This blueprint function combines all the extraction functions from the previous section. It neatly puts everything we want to extract in one place in the code so that the subsequent steps do not need to be adjusted if you add or change something here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "eeb97f3c-f69d-43de-9e77-e6be50100e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nlp(doc):\n",
    "    return { \n",
    "        'lemmas' : extract_lemmas(doc, \n",
    "                                  exclude_pos = ['PART', 'PUNCT', \n",
    "                                                 'DET', 'PRON', 'SYM', 'SPACE'],\n",
    "                                  filter_stops = False),\n",
    "        'adjs_verbs' : extract_lemmas(doc, include_pos = ['ADJ', 'VERB']),\n",
    "        'nouns' : extract_lemmas(doc, include_pos = ['NOUN', 'PROPN']),\n",
    "        'noun_phrases' : extract_noun_phrases(doc, ['NOUN']),\n",
    "        'adj_noun_phrases': extract_noun_phrases(doc, ['ADJ']),\n",
    "        'entities' : extract_entities(doc, ['PERSON', 'ORG', 'GPE', 'LOC'])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "001cec80-c00e-40f2-97b8-ef90546ac71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmas: ['good', 'friend', 'Ryan', 'Peters', 'like', 'fancy', 'adventure', 'game']\n",
      "adjs_verbs: ['good', 'like', 'fancy']\n",
      "nouns: ['friend', 'Ryan', 'Peters', 'adventure', 'game']\n",
      "noun_phrases: ['adventure_game']\n",
      "adj_noun_phrases: ['good_friend', 'fancy_adventure', 'fancy_adventure_game']\n",
      "entities: ['Ryan_Peters/PERSON']\n"
     ]
    }
   ],
   "source": [
    "text = \"My best friend Ryan Peters likes fancy adventure games.\"\n",
    "doc = nlp(text)\n",
    "for col, values in extract_nlp(doc).items():\n",
    "    print(f\"{col}: {values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "909ac486-74d8-4d78-a696-d028d8bee9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lemmas', 'adjs_verbs', 'nouns', 'noun_phrases', 'adj_noun_phrases', 'entities']\n"
     ]
    }
   ],
   "source": [
    "nlp_columns = list(extract_nlp(nlp.make_doc('')).keys())\n",
    "print(nlp_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ff481-f411-44c1-bbc3-532e1a3caec9",
   "metadata": {},
   "source": [
    "## **Blueprint: Using spaCy on a Large Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "18550c37-4b9a-441c-bab4-380c6d62e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"reddit-selfposts.db\"\n",
    "con = sqlite3.connect(db_name)\n",
    "df = pd.read_sql(\"select * from posts_cleaned\", con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c5f2a4ec-d7e3-40d7-a423-c5fd6b79eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['title'] + ': ' + df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "49e49cfb-1a34-4c87-8bb6-711921f79899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6d8knd</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>Remember your command line switches...</td>\n",
       "      <td>Hi there,  &lt;lb&gt;The usual. Long time lerker, fi...</td>\n",
       "      <td>writing/stories</td>\n",
       "      <td>tech support</td>\n",
       "      <td>Remember your command line switches...: Hi the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58mbft</td>\n",
       "      <td>teenmom</td>\n",
       "      <td>So what was Matt \"addicted\" to?</td>\n",
       "      <td>Did he ever say what his addiction was or is h...</td>\n",
       "      <td>tv_show</td>\n",
       "      <td>teen mom</td>\n",
       "      <td>So what was Matt \"addicted\" to?: Did he ever s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8f73s7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>No Club Colors</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "      <td>No Club Colors: Funny story. I went to college...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6ti6re</td>\n",
       "      <td>ringdoorbell</td>\n",
       "      <td>Not door bell, but floodlight mount height.</td>\n",
       "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
       "      <td>hardware/tools</td>\n",
       "      <td>doorbells</td>\n",
       "      <td>Not door bell, but floodlight mount height.: I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77sxto</td>\n",
       "      <td>intel</td>\n",
       "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
       "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
       "      <td>electronics</td>\n",
       "      <td>cpu</td>\n",
       "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             subreddit  \\\n",
       "0  6d8knd  talesfromtechsupport   \n",
       "1  58mbft               teenmom   \n",
       "2  8f73s7                Harley   \n",
       "3  6ti6re          ringdoorbell   \n",
       "4  77sxto                 intel   \n",
       "\n",
       "                                               title  \\\n",
       "0             Remember your command line switches...   \n",
       "1                    So what was Matt \"addicted\" to?   \n",
       "2                                     No Club Colors   \n",
       "3        Not door bell, but floodlight mount height.   \n",
       "4  Worried about my 8700k small fft/data stress r...   \n",
       "\n",
       "                                            raw_text         category  \\\n",
       "0  Hi there,  <lb>The usual. Long time lerker, fi...  writing/stories   \n",
       "1  Did he ever say what his addiction was or is h...          tv_show   \n",
       "2  Funny story. I went to college in Las Vegas. T...            autos   \n",
       "3  I know this is a sub for the 'Ring Doorbell' b...   hardware/tools   \n",
       "4  Prime95 (regardless of version) and OCCT both,...      electronics   \n",
       "\n",
       "       subcategory                                               text  \n",
       "0     tech support  Remember your command line switches...: Hi the...  \n",
       "1         teen mom  So what was Matt \"addicted\" to?: Did he ever s...  \n",
       "2  harley davidson  No Club Colors: Funny story. I went to college...  \n",
       "3        doorbells  Not door bell, but floodlight mount height.: I...  \n",
       "4              cpu  Worried about my 8700k small fft/data stress r...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89ceabe-d00a-43a6-b1c5-c614b43eabd5",
   "metadata": {},
   "source": [
    "Before we start NLP processing, we initialize the new DataFrame columns we want to fill with values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f89fa885-05df-4c4b-8b44-40e4ecfb422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in nlp_columns:\n",
    "    df[col] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab304b3-93d1-443b-8b40-971751e8f53a",
   "metadata": {},
   "source": [
    "spaCy’s neural models benefit from running on GPU. Thus, we try to load the model on the GPU before we start:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9f559ef3-9a25-4633-a413-7ce9c24ed008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found, working on CPU.\n"
     ]
    }
   ],
   "source": [
    "if spacy.prefer_gpu():\n",
    "    print(\"Working on GPU.\")\n",
    "else:\n",
    "    print(\"No GPU found, working on CPU.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4680c0b-3092-42b7-a4a7-89e9d3da5740",
   "metadata": {},
   "source": [
    "Now we have to decide which model and which of the pipeline components to use. Remember to disable unneccesary components to improve runtime! We stick to the small English model with the default pipeline and use our custom tokenizer that splits on hyphens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ba9f0035-682b-401c-b6d8-af8d6588421c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=[])\n",
    "nlp.tokenizer = custom_tokenizer(nlp) # optional"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e41df2-a475-4918-97b6-2474f22eb7b3",
   "metadata": {},
   "source": [
    "When processing larger datasets, it is recommended to use spaCy’s batch processing for a significant performance gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5a7baa-a9e2-4973-ade9-9444567baaec",
   "metadata": {},
   "source": [
    "The function nlp.pipe takes an iterable of texts, processes them internally as a batch, and yields a list of processed Doc objects in the same order as the input data.\n",
    "To use it, we first have to define a batch size. Then we can loop over the batches and call nlp.pipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282b5ebb-7836-4562-87e2-eccee06e6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "\n",
    "for i in range(0, len(df), batch_size):\n",
    "    \n",
    "    docs = nlp.pipe(df['text'][i:i+batch_size])\n",
    "\n",
    "    for j, doc in enumerate(docs):\n",
    "        for col, values in extract_nlp(doc).items():\n",
    "            df[col].iloc[i+j] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c5e43bd9-9d57-4655-827b-d38e86b997ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>raw_text</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>text</th>\n",
       "      <th>lemmas</th>\n",
       "      <th>adjs_verbs</th>\n",
       "      <th>nouns</th>\n",
       "      <th>noun_phrases</th>\n",
       "      <th>adj_noun_phrases</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6d8knd</td>\n",
       "      <td>talesfromtechsupport</td>\n",
       "      <td>Remember your command line switches...</td>\n",
       "      <td>Hi there,  &lt;lb&gt;The usual. Long time lerker, fi...</td>\n",
       "      <td>writing/stories</td>\n",
       "      <td>tech support</td>\n",
       "      <td>Remember your command line switches...: Hi the...</td>\n",
       "      <td>[remember, command, line, switch, hi, there, u...</td>\n",
       "      <td>[remember, usual, long, kind, right, independe...</td>\n",
       "      <td>[command, line, switch, time, lerker, time, po...</td>\n",
       "      <td>[command_line, command_line_switch, line_switc...</td>\n",
       "      <td>[long_time, long_time_lerker, first_time, firs...</td>\n",
       "      <td>[popularversioncontrol/PERSON, beta1/PERSON, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58mbft</td>\n",
       "      <td>teenmom</td>\n",
       "      <td>So what was Matt \"addicted\" to?</td>\n",
       "      <td>Did he ever say what his addiction was or is h...</td>\n",
       "      <td>tv_show</td>\n",
       "      <td>teen mom</td>\n",
       "      <td>So what was Matt \"addicted\" to?: Did he ever s...</td>\n",
       "      <td>[so, be, Matt, addict, to, do, ever, say, addi...</td>\n",
       "      <td>[addict, chug, talk, sober, edit, add, know, d...</td>\n",
       "      <td>[Matt, addiction, beer, addict, addict, group,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Matt/PERSON, NA/ORG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8f73s7</td>\n",
       "      <td>Harley</td>\n",
       "      <td>No Club Colors</td>\n",
       "      <td>Funny story. I went to college in Las Vegas. T...</td>\n",
       "      <td>autos</td>\n",
       "      <td>harley davidson</td>\n",
       "      <td>No Club Colors: Funny story. I went to college...</td>\n",
       "      <td>[Club, Colors, funny, story, go, to, college, ...</td>\n",
       "      <td>[funny, go, know, motorcycle, end, call, worth...</td>\n",
       "      <td>[Club, Colors, story, college, Las, Vegas, col...</td>\n",
       "      <td>[college_buddy, dance_club]</td>\n",
       "      <td>[funny_story, front_door, bright_color, much_b...</td>\n",
       "      <td>[Club_Colors_:/ORG, Las_Vegas/GPE, Hogs_Heifer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6ti6re</td>\n",
       "      <td>ringdoorbell</td>\n",
       "      <td>Not door bell, but floodlight mount height.</td>\n",
       "      <td>I know this is a sub for the 'Ring Doorbell' b...</td>\n",
       "      <td>hardware/tools</td>\n",
       "      <td>doorbells</td>\n",
       "      <td>Not door bell, but floodlight mount height.: I...</td>\n",
       "      <td>[door, bell, but, floodlight, mount, height, k...</td>\n",
       "      <td>[know, exist, drop, high, mount, say, ideal, m...</td>\n",
       "      <td>[door, bell, floodlight, mount, height, sub, R...</td>\n",
       "      <td>[door_bell, ground_level]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Floodlight/ORG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77sxto</td>\n",
       "      <td>intel</td>\n",
       "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
       "      <td>Prime95 (regardless of version) and OCCT both,...</td>\n",
       "      <td>electronics</td>\n",
       "      <td>cpu</td>\n",
       "      <td>Worried about my 8700k small fft/data stress r...</td>\n",
       "      <td>[worried, about, 8700k, small, fft, datum, str...</td>\n",
       "      <td>[worried, small, small, include, shoot, pure, ...</td>\n",
       "      <td>[fft, datum, stress, result, Prime95, version,...</td>\n",
       "      <td>[datum_stress, datum_stress_result, stress_res...</td>\n",
       "      <td>[small_fft, pure_stock, other_stress, other_st...</td>\n",
       "      <td>[Prime95/PERSON, OCCT/ORG, P95/ORG]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             subreddit  \\\n",
       "0  6d8knd  talesfromtechsupport   \n",
       "1  58mbft               teenmom   \n",
       "2  8f73s7                Harley   \n",
       "3  6ti6re          ringdoorbell   \n",
       "4  77sxto                 intel   \n",
       "\n",
       "                                               title  \\\n",
       "0             Remember your command line switches...   \n",
       "1                    So what was Matt \"addicted\" to?   \n",
       "2                                     No Club Colors   \n",
       "3        Not door bell, but floodlight mount height.   \n",
       "4  Worried about my 8700k small fft/data stress r...   \n",
       "\n",
       "                                            raw_text         category  \\\n",
       "0  Hi there,  <lb>The usual. Long time lerker, fi...  writing/stories   \n",
       "1  Did he ever say what his addiction was or is h...          tv_show   \n",
       "2  Funny story. I went to college in Las Vegas. T...            autos   \n",
       "3  I know this is a sub for the 'Ring Doorbell' b...   hardware/tools   \n",
       "4  Prime95 (regardless of version) and OCCT both,...      electronics   \n",
       "\n",
       "       subcategory                                               text  \\\n",
       "0     tech support  Remember your command line switches...: Hi the...   \n",
       "1         teen mom  So what was Matt \"addicted\" to?: Did he ever s...   \n",
       "2  harley davidson  No Club Colors: Funny story. I went to college...   \n",
       "3        doorbells  Not door bell, but floodlight mount height.: I...   \n",
       "4              cpu  Worried about my 8700k small fft/data stress r...   \n",
       "\n",
       "                                              lemmas  \\\n",
       "0  [remember, command, line, switch, hi, there, u...   \n",
       "1  [so, be, Matt, addict, to, do, ever, say, addi...   \n",
       "2  [Club, Colors, funny, story, go, to, college, ...   \n",
       "3  [door, bell, but, floodlight, mount, height, k...   \n",
       "4  [worried, about, 8700k, small, fft, datum, str...   \n",
       "\n",
       "                                          adjs_verbs  \\\n",
       "0  [remember, usual, long, kind, right, independe...   \n",
       "1  [addict, chug, talk, sober, edit, add, know, d...   \n",
       "2  [funny, go, know, motorcycle, end, call, worth...   \n",
       "3  [know, exist, drop, high, mount, say, ideal, m...   \n",
       "4  [worried, small, small, include, shoot, pure, ...   \n",
       "\n",
       "                                               nouns  \\\n",
       "0  [command, line, switch, time, lerker, time, po...   \n",
       "1  [Matt, addiction, beer, addict, addict, group,...   \n",
       "2  [Club, Colors, story, college, Las, Vegas, col...   \n",
       "3  [door, bell, floodlight, mount, height, sub, R...   \n",
       "4  [fft, datum, stress, result, Prime95, version,...   \n",
       "\n",
       "                                        noun_phrases  \\\n",
       "0  [command_line, command_line_switch, line_switc...   \n",
       "1                                                 []   \n",
       "2                        [college_buddy, dance_club]   \n",
       "3                          [door_bell, ground_level]   \n",
       "4  [datum_stress, datum_stress_result, stress_res...   \n",
       "\n",
       "                                    adj_noun_phrases  \\\n",
       "0  [long_time, long_time_lerker, first_time, firs...   \n",
       "1                                                 []   \n",
       "2  [funny_story, front_door, bright_color, much_b...   \n",
       "3                                                 []   \n",
       "4  [small_fft, pure_stock, other_stress, other_st...   \n",
       "\n",
       "                                            entities  \n",
       "0  [popularversioncontrol/PERSON, beta1/PERSON, d...  \n",
       "1                              [Matt/PERSON, NA/ORG]  \n",
       "2  [Club_Colors_:/ORG, Las_Vegas/GPE, Hogs_Heifer...  \n",
       "3                                   [Floodlight/ORG]  \n",
       "4                [Prime95/PERSON, OCCT/ORG, P95/ORG]  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "98845aa3-17d4-4a7b-84df-e2fd65441060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_words(df, 'noun_phrases').head(10).plot(kind='barh').invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf0fd0-29d4-4f8e-8815-e22d08cadb28",
   "metadata": {},
   "source": [
    "**Saving the result in the database**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6b5310-7e27-41ef-90ab-621f337d517c",
   "metadata": {},
   "source": [
    "Cannot save due to unsupported type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8dafa9-7854-46e2-859b-8cd4c998bf74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
